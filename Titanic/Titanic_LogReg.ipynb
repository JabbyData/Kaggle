{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.770050888Z",
     "start_time": "2024-04-17T15:30:07.762492924Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Dependencies ####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#### Loading the data ####\n",
    "train_set = pd.read_csv(\"Data/train.csv\")\n",
    "test_set = pd.read_csv(\"Data/test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.832432409Z",
     "start_time": "2024-04-17T15:30:07.769529817Z"
    }
   },
   "id": "6fa20757fa35130a",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#### Getting rid of useless column ####\n",
    "def drop_columns(data, columns):\n",
    "    for column in columns:\n",
    "        data.drop(column, axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "train_set = drop_columns(train_set, [\"PassengerId\",\"Name\", \"Ticket\", \"Fare\", \"Cabin\"])\n",
    "test_set = drop_columns(test_set, [\"PassengerId\",\"Name\", \"Ticket\", \"Fare\", \"Cabin\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.833241519Z",
     "start_time": "2024-04-17T15:30:07.827830967Z"
    }
   },
   "id": "858bfb73ff1fc3a5",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train report : \n",
      "Age has 177 missing values\n",
      "Embarked has 2 missing values\n",
      "Test report : \n",
      "Age has 86 missing values\n"
     ]
    }
   ],
   "source": [
    "#### Checking the data ####\n",
    "def missing_report(dataset):\n",
    "    for feature in dataset.columns:\n",
    "        if np.dtype(dataset[feature]) == \"object\":\n",
    "            # categorical feature\n",
    "            misses = dataset[feature].isnull().sum() + dataset[feature].isna().sum() + dataset[feature].values.tolist().count(\"\")\n",
    "            if misses > 0:\n",
    "                print(f\"{feature} has {dataset[feature].isnull().sum()} missing values\")\n",
    "        else:\n",
    "            # numerical feature\n",
    "            misses = dataset[feature].isnull().sum() + dataset[feature].isna().sum()\n",
    "            if misses > 0:\n",
    "                print(f\"{feature} has {dataset[feature].isnull().sum()} missing values\")\n",
    "\n",
    "\n",
    "print(\"Train report : \")\n",
    "missing_report(train_set)\n",
    "\n",
    "print(\"Test report : \")\n",
    "missing_report(test_set)\n",
    "\n",
    "# Age has missing values, we need to take care of it"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.833876069Z",
     "start_time": "2024-04-17T15:30:07.828130413Z"
    }
   },
   "id": "6d9c72e6242a380e",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15612/4094785868.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[feature].fillna(dataset[feature].median(), inplace=True)\n",
      "/tmp/ipykernel_15612/4094785868.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[feature].fillna(dataset[feature].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#### Filling missing values ####\n",
    "# For embarked, we will drop the missing values\n",
    "train_set.dropna(subset=[\"Embarked\"], inplace=True)\n",
    "\n",
    "# For Age, we will perform a tracked imputation by filling the missing values with the median\n",
    "def track_impute(dataset, feature):\n",
    "    # index containing missing values\n",
    "    missing_index = dataset[dataset[feature].isna()].index\n",
    "    dataset[feature + 'Missing'] = False\n",
    "    dataset.loc[missing_index, feature + 'Missing'] = True\n",
    "    dataset[feature].fillna(dataset[feature].median(), inplace=True)\n",
    "    return dataset\n",
    "\n",
    "train_set = track_impute(train_set, \"Age\")\n",
    "test_set = track_impute(test_set, \"Age\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.834748325Z",
     "start_time": "2024-04-17T15:30:07.828264144Z"
    }
   },
   "id": "dc68a9c756521f1c",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Classifier Accuracy :  0.6175478065241845\n"
     ]
    }
   ],
   "source": [
    "#### Performing AdaBoost ####\n",
    "# Basic Classifier to compare with AdaBoost\n",
    "print(\"Basic Classifier Accuracy : \",sum(train_set[\"Survived\"] == 0)/len(train_set))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.834984058Z",
     "start_time": "2024-04-17T15:30:07.828347736Z"
    }
   },
   "id": "a50e4f7480973645",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#### Preprocessing the data ####\n",
    "# We need to convert the categorical features to numerical, here label encoding is enough for 2 levels\n",
    "def one_hot_encode(dataset, features):\n",
    "    for feature in features:\n",
    "        dataset = pd.concat([dataset, pd.get_dummies(dataset[feature], prefix=feature)], axis=1)\n",
    "        dataset.drop(feature, axis=1, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "# train_set = hot_one_encode(train_set,[\"Sex\",\"AgeMissing\"])\n",
    "train_set = one_hot_encode(train_set,[\"Pclass\",\"Sex\",\"AgeMissing\",\"Embarked\"])\n",
    "test_set = one_hot_encode(test_set,[\"Pclass\",\"Sex\",\"AgeMissing\",\"Embarked\"])\n",
    "\n",
    "# We need to scale the numerical data to have a better performance\n",
    "def scale_data(dataset, features):\n",
    "    scaler = StandardScaler()\n",
    "    dataset[features] = scaler.fit_transform(dataset[features])\n",
    "    return dataset\n",
    "\n",
    "train_set = scale_data(train_set, [\"Age\"])\n",
    "test_set = scale_data(test_set, [\"Age\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.835720191Z",
     "start_time": "2024-04-17T15:30:07.828432833Z"
    }
   },
   "id": "b9882d9357c335a7",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Survived       Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n0         0 -0.563674      1      0     False     False      True       False   \n1         1  0.669217      1      0      True     False     False        True   \n2         1 -0.255451      0      0     False     False      True        True   \n3         1  0.438050      1      0      True     False     False        True   \n4         0  0.438050      0      0     False     False      True       False   \n\n   Sex_male  AgeMissing_False  AgeMissing_True  Embarked_C  Embarked_Q  \\\n0      True              True            False       False       False   \n1     False              True            False        True       False   \n2     False              True            False       False       False   \n3     False              True            False       False       False   \n4      True              True            False       False       False   \n\n   Embarked_S  \n0        True  \n1       False  \n2        True  \n3        True  \n4        True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>AgeMissing_False</th>\n      <th>AgeMissing_True</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-0.563674</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.669217</td>\n      <td>1</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-0.255451</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.438050</td>\n      <td>1</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.438050</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.904930961Z",
     "start_time": "2024-04-17T15:30:07.840414835Z"
    }
   },
   "id": "2b197f2d5098a6ba",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### Building the Log Reg model ###\n",
    "X= train_set.drop(\"Survived\", axis=1)\n",
    "y = train_set[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg_model = log_reg.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.905345399Z",
     "start_time": "2024-04-17T15:30:07.856893541Z"
    }
   },
   "id": "c187e4a24a974e91",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8146067415730337\n"
     ]
    }
   ],
   "source": [
    "#### Predicting the test set ####\n",
    "y_preds = log_reg_model.predict(X_test)\n",
    "print(\"Accuracy : \", metrics.accuracy_score(y_test, y_preds))  # this is better than the basic classifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.906982318Z",
     "start_time": "2024-04-17T15:30:07.899082266Z"
    }
   },
   "id": "da52ecbfa1928347",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#### Fit on the whole dataset #####\n",
    "log_reg_model = log_reg.fit(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.907353877Z",
     "start_time": "2024-04-17T15:30:07.899285645Z"
    }
   },
   "id": "49bf80c5eab17416",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#### Predicting the test set and render it to the Kaggle submission format ####\n",
    "titanic_preds = log_reg_model.predict(test_set)\n",
    "submission = pd.DataFrame({\"PassengerId\": range(892,1310), \"Survived\": titanic_preds})\n",
    "submission_path = \"Data/titanic_submission.csv\"\n",
    "\n",
    "# Save the CSV file to the repository\n",
    "with open(submission_path, \"w\") as file:\n",
    "    submission.to_csv(file, index=False)\n",
    "\n",
    "print(\"finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:30:07.908037068Z",
     "start_time": "2024-04-17T15:30:07.899376486Z"
    }
   },
   "id": "e6d7f82c46eb0bb2",
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
