{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.071889420Z",
     "start_time": "2024-04-17T15:17:47.061433620Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Dependencies ####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "#### Loading the data ####\n",
    "train_set = pd.read_csv(\"Data/train.csv\")\n",
    "test_set = pd.read_csv(\"Data/test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.126875211Z",
     "start_time": "2024-04-17T15:17:47.077135616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Checking the data ####\n",
    "train_set.describe()\n",
    "train_set.info()\n",
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.146453410Z",
     "start_time": "2024-04-17T15:17:47.127240621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "#### Getting rid of useless column ####\n",
    "def drop_columns(data, columns):\n",
    "    for column in columns:\n",
    "        data.drop(column, axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "train_set = drop_columns(train_set, [\"PassengerId\",\"Name\", \"Ticket\", \"Fare\", \"Cabin\"])\n",
    "test_set = drop_columns(test_set, [\"PassengerId\",\"Name\", \"Ticket\", \"Fare\", \"Cabin\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.191392890Z",
     "start_time": "2024-04-17T15:17:47.132405035Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train report : \n",
      "Age has 177 missing values\n",
      "Embarked has 2 missing values\n",
      "Test report : \n",
      "Age has 86 missing values\n"
     ]
    }
   ],
   "source": [
    "#### Checking the data ####\n",
    "def missing_report(dataset):\n",
    "    for feature in dataset.columns:\n",
    "        if np.dtype(dataset[feature]) == \"object\":\n",
    "            # categorical feature\n",
    "            misses = dataset[feature].isnull().sum() + dataset[feature].isna().sum() + dataset[feature].values.tolist().count(\"\")\n",
    "            if misses > 0:\n",
    "                print(f\"{feature} has {dataset[feature].isnull().sum()} missing values\")\n",
    "        else:\n",
    "            # numerical feature\n",
    "            misses = dataset[feature].isnull().sum() + dataset[feature].isna().sum()\n",
    "            if misses > 0:\n",
    "                print(f\"{feature} has {dataset[feature].isnull().sum()} missing values\")\n",
    "\n",
    "\n",
    "print(\"Train report : \")\n",
    "missing_report(train_set)\n",
    "\n",
    "print(\"Test report : \")\n",
    "missing_report(test_set)\n",
    "\n",
    "# Age has missing values, we need to take care of it"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.192135298Z",
     "start_time": "2024-04-17T15:17:47.150545882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14127/4094785868.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[feature].fillna(dataset[feature].median(), inplace=True)\n",
      "/tmp/ipykernel_14127/4094785868.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[feature].fillna(dataset[feature].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#### Filling missing values ####\n",
    "# For embarked, we will drop the missing values\n",
    "train_set.dropna(subset=[\"Embarked\"], inplace=True)\n",
    "\n",
    "# For Age, we will perform a tracked imputation by filling the missing values with the median\n",
    "def track_impute(dataset, feature):\n",
    "    # index containing missing values\n",
    "    missing_index = dataset[dataset[feature].isna()].index\n",
    "    dataset[feature + 'Missing'] = False\n",
    "    dataset.loc[missing_index, feature + 'Missing'] = True\n",
    "    dataset[feature].fillna(dataset[feature].median(), inplace=True)\n",
    "    return dataset\n",
    "\n",
    "train_set = track_impute(train_set, \"Age\")\n",
    "test_set = track_impute(test_set, \"Age\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.215408310Z",
     "start_time": "2024-04-17T15:17:47.191168285Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Classifier Accuracy :  0.6175478065241845\n"
     ]
    }
   ],
   "source": [
    "#### Performing AdaBoost ####\n",
    "# Basic Classifier to compare with AdaBoost\n",
    "print(\"Basic Classifier Accuracy : \",sum(train_set[\"Survived\"] == 0)/len(train_set))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.327306673Z",
     "start_time": "2024-04-17T15:17:47.197307646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "#### Preprocessing the data ####\n",
    "# We need to convert the categorical features to numerical, here label encoding is enough for 2 levels\n",
    "def one_hot_encode(dataset, features):\n",
    "    for feature in features:\n",
    "        dataset = pd.concat([dataset, pd.get_dummies(dataset[feature], prefix=feature)], axis=1)\n",
    "        dataset.drop(feature, axis=1, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "# train_set = hot_one_encode(train_set,[\"Sex\",\"AgeMissing\"])\n",
    "train_set = one_hot_encode(train_set,[\"Pclass\",\"Sex\",\"AgeMissing\",\"Embarked\"])\n",
    "test_set = one_hot_encode(test_set,[\"Pclass\",\"Sex\",\"AgeMissing\",\"Embarked\"])\n",
    "\n",
    "# We need to scale the numerical data to have a better performance\n",
    "def scale_data(dataset, features):\n",
    "    scaler = StandardScaler()\n",
    "    dataset[features] = scaler.fit_transform(dataset[features])\n",
    "    return dataset\n",
    "\n",
    "train_set = scale_data(train_set, [\"Age\"])\n",
    "test_set = scale_data(test_set, [\"Age\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.328963072Z",
     "start_time": "2024-04-17T15:17:47.260439415Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Survived       Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n0         0 -0.563674      1      0     False     False      True       False   \n1         1  0.669217      1      0      True     False     False        True   \n2         1 -0.255451      0      0     False     False      True        True   \n3         1  0.438050      1      0      True     False     False        True   \n4         0  0.438050      0      0     False     False      True       False   \n\n   Sex_male  AgeMissing_False  AgeMissing_True  Embarked_C  Embarked_Q  \\\n0      True              True            False       False       False   \n1     False              True            False        True       False   \n2     False              True            False       False       False   \n3     False              True            False       False       False   \n4      True              True            False       False       False   \n\n   Embarked_S  \n0        True  \n1       False  \n2        True  \n3        True  \n4        True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>AgeMissing_False</th>\n      <th>AgeMissing_True</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-0.563674</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.669217</td>\n      <td>1</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-0.255451</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.438050</td>\n      <td>1</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.438050</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.397362033Z",
     "start_time": "2024-04-17T15:17:47.333281185Z"
    }
   },
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "### Building the model, we want to observe some results so we split the training set before complete evaluation ###\n",
    "abc = AdaBoostClassifier(n_estimators=100)\n",
    "X= train_set.drop(\"Survived\", axis=1)\n",
    "y = train_set[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "abc_model = abc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.598343381Z",
     "start_time": "2024-04-17T15:17:47.399910946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8033707865168539\n"
     ]
    }
   ],
   "source": [
    "#### Predicting the test set ####\n",
    "y_preds = abc_model.predict(X_test)\n",
    "print(\"Accuracy : \", metrics.accuracy_score(y_test, y_preds)) # this is better than the basic classifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.601149260Z",
     "start_time": "2024-04-17T15:17:47.560897977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "#### Tuning the model ####\n",
    "# We will perform a grid search to find the best hyperparameters\n",
    "# param_grid = {'learning_rate': np.linspace(0.1, 1, 20), 'n_estimators': np.arange(20, 200, 20)}\n",
    "# grid_search = GridSearchCV(estimator=abc, param_grid=param_grid, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best learning rate\n",
    "# best_learning_rate = grid_search.best_params_['learning_rate']\n",
    "# best_n_estimators = grid_search.best_params_['n_estimators']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.601992624Z",
     "start_time": "2024-04-17T15:17:47.588934176Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8033707865168539\n"
     ]
    }
   ],
   "source": [
    "#### Rebuilding the model with the best hyperparameters ####\n",
    "# lr = best_learning_rate # 0.7157894736842105\n",
    "# nb_est = best_n_estimators # 80\n",
    "lr = 0.7157894736842105\n",
    "nb_est = 80\n",
    "abc_tuned = AdaBoostClassifier(n_estimators=nb_est, learning_rate=lr)\n",
    "abc_tuned_model = abc_tuned.fit(X_train, y_train)\n",
    "print(\"Accuracy : \", metrics.accuracy_score(y_test, abc_tuned_model.predict(X_test))) # this is better than the basic classifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.769937799Z",
     "start_time": "2024-04-17T15:17:47.601818701Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "#### Fitting the model on the whole training set ####\n",
    "abc_model = abc_tuned_model.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.826420469Z",
     "start_time": "2024-04-17T15:17:47.755093605Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#### Predicting the test set and render it to the Kaggle submission format ####\n",
    "titanic_preds = abc_model.predict(test_set)\n",
    "submission = pd.DataFrame({\"PassengerId\": range(892,1310), \"Survived\": titanic_preds})\n",
    "submission_path = \"Data/titanic_submission.csv\"\n",
    "\n",
    "# Save the CSV file to the repository\n",
    "with open(submission_path, \"w\") as file:\n",
    "    submission.to_csv(file, index=False)\n",
    "\n",
    "print(\"finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:17:47.875461718Z",
     "start_time": "2024-04-17T15:17:47.829727198Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
